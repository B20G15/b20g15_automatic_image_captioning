{"cells":[{"cell_type":"markdown","metadata":{"id":"dwP9y0lfrRSi"},"source":["# Image Captioning Project\n","\n","This project is to define and train an image-to-caption model, that can produce descriptions for real world images!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4M4AYTbrhYH"},"outputs":[],"source":["# ! shred -u setup_google_colab.py\n","# ! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n","# import setup_google_colab\n","# # please, uncomment the week you're working on\n","# # setup_google_colab.setup_week1()\n","# # setup_google_colab.setup_week2()\n","# # setup_google_colab.setup_week3()\n","# # setup_google_colab.setup_week4()\n","# # setup_google_colab.setup_week5()\n","# setup_google_colab.setup_week6()\n","\n","# # If you're using the old version of the course (check a path of notebook on Coursera, you'll see v1 or v2),\n","# # use setup_week2_old()."]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2017-08-27T10:16:46.508273Z","start_time":"2017-08-27T10:16:46.506062Z"},"id":"lfT8LlzgrRSp"},"source":["# Import stuff"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2017-09-17T12:30:35.584796Z","start_time":"2017-09-17T12:30:35.581343Z"},"id":"-AOL1WDJrRSv"},"outputs":[],"source":["# import sys\n","# sys.path.append(\"..\")\n","# import grading\n","# import download_utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JmSDu-ecrRS-"},"outputs":[],"source":["# download_utils.link_all_keras_resources()"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2017-09-17T14:32:05.229736Z","start_time":"2017-09-17T14:31:56.495874Z"},"id":"avIdNIXxrRTN"},"outputs":[],"source":["# import tensorflow as tf\n","# from tensorflow.contrib import keras\n","# import numpy as np\n","# %matplotlib inline\n","# import matplotlib.pyplot as plt\n","# L = keras.layers\n","# K = keras.backend\n","# import utils\n","# import time\n","# import zipfile\n","# import json\n","# from collections import defaultdict\n","# import re\n","# import random\n","# from random import choice\n","# import grading_utils\n","# import os\n","# from keras_utils import reset_tf_session\n","# import tqdm_utils"]},{"cell_type":"code","source":["# Import Libraries\n","# import matplotlib.pyplot as plt\n","# import torch\n","# from torch import nn\n","# from torch import optim\n","# import torch.nn.functional as F\n","#\n","# from torch.autograd import Variable\n","\n","# from PIL import Image\n","\n","# import pandas as pd\n","# import numpy as np\n","#\n","\n","# from mpl_toolkits.mplot3d import Axes3D\n","\n","# from pickle import dump\n","# from collections import OrderedDict\n","# from scipy.spatial.distance import cdist\n","# from sklearn.cluster import KMeans\n","# from sklearn.decomposition import PCA\n","# from sklearn import metrics\n","\n","# from keras import models\n","# from keras.applications import VGG16\n","# #from keras.preprocessing.image import load_img, img_to_array\n","# from keras.utils import load_img, img_to_array\n","# from keras.applications.vgg16 import preprocess_input\n","\n","from IPython import get_ipython\n","import sys, time, os, warnings\n","from google.colab import drive\n","from zipfile import ZipFile\n","import torch\n","# from torch import nn\n","# from torch import optim\n","# import torch.nn.functional as F\n","# from torch.autograd import Variable\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import ImageFolder"],"metadata":{"id":"fg04_7yt5n2Z","executionInfo":{"status":"ok","timestamp":1687069861310,"user_tz":-330,"elapsed":368,"user":{"displayName":"automatic imagecaption","userId":"15960113411930990751"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i_x_zqAkrRTn"},"source":["# Download data\n","\n","Flicker8k dataset has been used for this project.\n","\n","Dataset Link: GitHub - goodwillyoga/Flickr8k_dataset"]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"id":"lvVJJSRN4orc","executionInfo":{"status":"ok","timestamp":1687068021350,"user_tz":-330,"elapsed":39871,"user":{"displayName":"automatic imagecaption","userId":"15960113411930990751"}},"outputId":"3221d8fc-4d08-4190-f9a2-918b5e03c06c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#Unzip data source and destination environment\n","src_img_file_location = \"/content/drive/MyDrive/Dataset/Flickr8k_Dataset.zip\"\n","src_img_txt_file_location = \"/content/drive/MyDrive/Dataset/Flickr8k_text.zip\"\n","src_img_cpt_file_location = \"/content/drive/MyDrive/Dataset/captions.txt.zip\"\n","\n","dest_img_file_location = \"/content/drive/MyDrive/wrk_dir/Flickr8k_Dataset\"\n","dest_img_txt_file_location = \"/content/drive/MyDrive/wrk_dir/txt\"\n","dest_img_cpt_file_location = \"/content/drive/MyDrive/wrk_dir/cpt\""],"metadata":{"id":"-Os4NfTuE2nQ","executionInfo":{"status":"ok","timestamp":1687068244144,"user_tz":-330,"elapsed":398,"user":{"displayName":"automatic imagecaption","userId":"15960113411930990751"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# loading the .zip and creating a zip object\n","with ZipFile(src_img_file_location) as zObject:\n","\n","    # Extracting all the members of the zip\n","    # into a specific location.\n","    zObject.extractall(path = dest_img_file_location)"],"metadata":{"id":"KqzJYVdhFZvU","executionInfo":{"status":"ok","timestamp":1687068194740,"user_tz":-330,"elapsed":370,"user":{"displayName":"automatic imagecaption","userId":"15960113411930990751"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["with ZipFile(src_img_txt_file_location) as zObject:\n","    zObject.extractall(path = dest_img_txt_file_location)"],"metadata":{"id":"Lsxnf2K1ID6Q","executionInfo":{"status":"ok","timestamp":1687068747761,"user_tz":-330,"elapsed":1011,"user":{"displayName":"automatic imagecaption","userId":"15960113411930990751"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["with ZipFile(src_img_cpt_file_location) as zObject:\n","    zObject.extractall(path = dest_img_cpt_file_location)"],"metadata":{"id":"zc0VYq2tD64b","executionInfo":{"status":"ok","timestamp":1687068752356,"user_tz":-330,"elapsed":1038,"user":{"displayName":"automatic imagecaption","userId":"15960113411930990751"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Load data\n","images_dir = os.listdir(\"/content/Flicker8k_Dataset\")\n","\n","images_path = './Flicker8k_Dataset/'\n","captions_path = './Flicker8k_Dataset/Flickr_TextData/Flickr8k.token.txt'\n","train_path = './Flicker8k_Dataset/Flickr_TextData/Flickr_8k.trainImages.txt'\n","val_path = './Flicker8k_Dataset/Flickr_TextData/Flickr_8k.devImages.txt'\n","test_path = './Flicker8k_Dataset/Flickr_TextData/Flickr_8k.testImages.txt'\n","\n","# captions = open(captions_path, 'r').read().split(\"\\n\")\n","# x_train = open(train_path, 'r').read().split(\"\\n\")\n","# x_val = open(val_path, 'r').read().split(\"\\n\")\n","# x_test = open(test_path, 'r').read().split(\"\\n\")"],"metadata":{"id":"LvSfy2a-4zjm","executionInfo":{"status":"ok","timestamp":1687067129540,"user_tz":-330,"elapsed":382,"user":{"displayName":"automatic imagecaption","userId":"15960113411930990751"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# from numpy import expand_dims\n","image_size = (128,128)\n","\n","# YOUR CODE HERE for defining Transformation for an image\n","transform = transforms.Compose([\n","    transforms.Resize(image_size),\n","    transforms.Grayscale(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5], std=[0.5])\n","])"],"metadata":{"id":"zpUK9E2p9Mdc","executionInfo":{"status":"ok","timestamp":1687069430974,"user_tz":-330,"elapsed":383,"user":{"displayName":"automatic imagecaption","userId":"15960113411930990751"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# YOUR CODE HERE for the DataLoader\n","train_data = ImageFolder(dest_img_file_location, transform=transform)\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)"],"metadata":{"id":"F-exmB0B9NsZ","executionInfo":{"status":"ok","timestamp":1687069496098,"user_tz":-330,"elapsed":1008,"user":{"displayName":"automatic imagecaption","userId":"15960113411930990751"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device = torch.device(\"cuda\")\n","print(device)"],"metadata":{"id":"-j8STThi9UAm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687069868381,"user_tz":-330,"elapsed":353,"user":{"displayName":"automatic imagecaption","userId":"15960113411930990751"}},"outputId":"4d97c93c-724f-4547-b3d4-c740a083169c"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/B20G15/b20g15_automatic_image_captioning/blob/main/Image%20captioning%20using%20CNN%20%26%20RNN.ipynb","timestamp":1687065905338}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}